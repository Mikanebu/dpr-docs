# Core Datasets

*Important, commonly-used datasets as high quality, easy-to-use & open data packages*

Core Datasets are important, commonly-used **"core" datasets** like GDP or country codes made available as **high-quality**, **easy-to-use** and **open** [data packages][dp]. Find them online here on the DataHub:

http://datapackaged.com/core/

Key features are:

* **High Quality & Reliable** -- sourcing, normalizing and quality checking a set of **key reference and indicator datasets such as country codes, currencies, GDP and population**
* **Standardized & Bulk** -- all datasets provided in a **standardized** form and can be accessed in **bulk as CSV** together with a simple **JSON schema**
* **Versioned & Packaged** -- all data is in **data packages** and is **versioned** using git so all changes are visible and data can be **collaboratively maintained**

The "Core Datasets" effort is part of the broader [Frictionless Data initiative][frictionless].

[frictionless]: http://frictionlessdata.io/
[dp]: http://frictionlessdata.io/data-packages/
[tdp]: http://data.okfn.org/doc/tabular-data-package/
[od]: http://opendefinition.org/

<img src="http://assets.okfn.org/p/data/img/icon-128.png" alt="" style="display: block; margin: auto;" />

<a name="curators" id="curators"></a>

## Core Data Curators

The Core Data Curators curate the core datasets.

Curation involves identifying and locating core (public) datasets, then packaging them up as high-quality, reliable, and easy-to-use [data packages][dp] (standardized, structured, open).

**New team members wanted:** We are always seeking volunteers to join the Data Curators team. Get to be part of a crack team and develop and hone your data wrangling skills whilst helping to provide high quality data to the community.

* **Anyone can contribute**: details on the [roles and skills needed below](#roles).
* **Get involved**: read more below or jump straight to [the sign-up section](#sign-up).
* **[Data Curators Guide][guide]**: can't wait to get started as a Data Curator? You can dive straight in and start packaging datasets using the [core data curators guide][guide].

[guide]: /publishers/core-data-curators/

<iframe src="https://docs.google.com/presentation/d/1-BLImNBv2RtEkFVq_DdWjy05baHfprWHHdXZiMrmihQ/embed?start=false&loop=false&delayms=3000" frameborder="0" width="480" height="389" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

<a name="sign-up" id="sign-up"></a>

### What Roles and Skills are Needed

We have a variety of roles from identifying new "core" datasets, to collecting and packaging the data, to performing quality control.

**Core Skills** -- at least one of these skills is strongly recommended:

* **Data Wrangling Experience**. Many of our source datasets are not complex (just an Excel file or similar) and can be "wrangled" in a Spreadsheet program. What we therefore recommend is at least one of:
    * Experience with a Spreadsheet application such as Excel or (preferably) Google Docs including use of formulas and (desirably) macros (you should at least know how you could quickly convert a cell containing '2014' to '2014-01-01' across 1000 rows)
    * Coding for data processing (especially scraping) in one or more of python, javascript, bash
* **Data sleuthing** - the ability to dig up data on the web (specific desirable skills: you know how to search by filetype in google, you know where the developer tools are in chrome or firefox, you know how to find the URL a form posts to)

**Desirable Skills** (the more the better!):

* Data vs Metadata: know difference between data and metadata
* Familiarity with Git (and Github)
* Familiarity with a command line (preferably bash)
* Know what JSON is
* Mac or Unix is your default operating system (will make access to relevant tools that much easier)
* Knowledge of Web APIs and/or HTML
* Use of curl or similar command line tool for accessing Web APIs or web pages
* Scraping using a command line tool or (even better) by coding yourself
* Know what a Data Package and a Tabular Data Package are
* Know what a text editor is (e.g. notepad, textmate, vim, emacs, ...) and know how to use it (useful for both working with data and for editing Data Package metadata)

<a name="sign-up" id="sign-up"></a>

### Get Involved - Sign Up Now!

Here's what you need to know when you sign up:

* **Time commitment**: Members of the team commit to at least 8-16h per month (though this will be an average - if you are especially busy with other things one month and do less that is fine)
* **Schedule**: There is no schedule so you can contribute at any time that is good for you - evenings, weekeneds, lunch-times etc
* **Location**: all activity will be carried out online so you can be based anywhere in the world
* **Skills**: see above

To register your interest fill in the following form. Any questions, please [get in touch directly][contact].

<iframe src="https://docs.google.com/forms/d/1d9chMK0jU9CJs0_mnK_JQU9iIJocjm7AEp0ZM5eSiNg/viewform?embedded=true" width="620" height="1425" frameborder="0" marginheight="0" marginwidth="0">Loading...</iframe>

[contact]: /contact/

<!--
* Important and commonly-used: e.g. reference data such as country codes and currencies or indicators such as inflation, GDP and population.
* High quality, easy-to-use: quality checked data provided in a **standardized** form as **versioned data packages** with the data accessible in **bulk** as CSV with a simple **JSON schema**
* Open: all datasets are [open data as per the Open Definition][od] - free to use, build on and share.

Sourced, packaged and maintained by the Core Data Curators team this is data you can rely on.

-->

