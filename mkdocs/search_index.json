{
    "docs": [
        {
            "location": "/", 
            "text": "DataHub Documentation\n\n\nWelcome to the DataHub documentation. Choose the appropriate section and dive right in!\n\n\nSections\n\n\n\n\nFor developers\n: \n3 Python, JavaScript and data pipelines? Start here!\n\n\nFor publishers\n: Want to store your data on DataHub? Start here!", 
            "title": "Home"
        }, 
        {
            "location": "/#datahub-documentation", 
            "text": "Welcome to the DataHub documentation. Choose the appropriate section and dive right in!", 
            "title": "DataHub Documentation"
        }, 
        {
            "location": "/#sections", 
            "text": "For developers :  3 Python, JavaScript and data pipelines? Start here!  For publishers : Want to store your data on DataHub? Start here!", 
            "title": "Sections"
        }, 
        {
            "location": "/developers/", 
            "text": "Developers\n\n\nThis section of the DataHub documentation is for developers. Here you can learn about the design of the platform and how to get DataHub running locally or on your own servers, and the process for contributing enhancements and bug fixes to the code.\n\n\n\n\nWe use following repositories on GitHub and GitLab for our platform:\n\n\n\n\nDPR API\n - API and web-application\n\n\nDPR JS\n - Visualizations and front-end JS\n\n\nDPR DOCS\n - Documentations\n\n\n\n\n\ngraph LR\n\nsubgraph Repos\n  dprapi[DPR API]\n  dprjs[DPR JS]\n  dprdeploy[DPR Deploy]\n  dprdocs[DPR Docs]\n  dprjs --submodule--> dprapi\nend\n\nsubgraph Sites\n  dhio[data.xxx]\n  dhdocs[docs.data.xxx]\n  dprdocs --> dhdocs\nend\n\ndeploy((Deploy))\ndprapi --> deploy\ndeploy --> dhio\ndprdeploy --> deploy\n\n\n\n\nInstall\n\n\nTo install the platform locally for development purposes, please follow the instructions here:\n\n\nhttps://github.com/frictionlessdata/dpr-api\n\n\nDeploy\n\n\nFor deployment of the application in a production environment, please see \nthe deploy page\n.\n\n\nAuthorization\n\n\nThe authorization set up enables system to restricts user permission to execute.\n\n\n\n\nAuthorization docs\n\n\n\n\nAuthentication\n\n\nSome DataHub API methods require client to provide user identity. API Client can use JWT token to perform authenticated requests.\n\n\n\n\nAuthentication docs\n\n\n\n\nCLI\n\n\nThe DataHub CLI (dpm) is a Python lib and command line interface to interact with an DataHub instance.\n\n\n\n\nCLI code", 
            "title": "Getting started"
        }, 
        {
            "location": "/developers/#developers", 
            "text": "This section of the DataHub documentation is for developers. Here you can learn about the design of the platform and how to get DataHub running locally or on your own servers, and the process for contributing enhancements and bug fixes to the code.   We use following repositories on GitHub and GitLab for our platform:   DPR API  - API and web-application  DPR JS  - Visualizations and front-end JS  DPR DOCS  - Documentations   \ngraph LR\n\nsubgraph Repos\n  dprapi[DPR API]\n  dprjs[DPR JS]\n  dprdeploy[DPR Deploy]\n  dprdocs[DPR Docs]\n  dprjs --submodule--> dprapi\nend\n\nsubgraph Sites\n  dhio[data.xxx]\n  dhdocs[docs.data.xxx]\n  dprdocs --> dhdocs\nend\n\ndeploy((Deploy))\ndprapi --> deploy\ndeploy --> dhio\ndprdeploy --> deploy", 
            "title": "Developers"
        }, 
        {
            "location": "/developers/#install", 
            "text": "To install the platform locally for development purposes, please follow the instructions here:  https://github.com/frictionlessdata/dpr-api", 
            "title": "Install"
        }, 
        {
            "location": "/developers/#deploy", 
            "text": "For deployment of the application in a production environment, please see  the deploy page .", 
            "title": "Deploy"
        }, 
        {
            "location": "/developers/#authorization", 
            "text": "The authorization set up enables system to restricts user permission to execute.   Authorization docs", 
            "title": "Authorization"
        }, 
        {
            "location": "/developers/#authentication", 
            "text": "Some DataHub API methods require client to provide user identity. API Client can use JWT token to perform authenticated requests.   Authentication docs", 
            "title": "Authentication"
        }, 
        {
            "location": "/developers/#cli", 
            "text": "The DataHub CLI (dpm) is a Python lib and command line interface to interact with an DataHub instance.   CLI code", 
            "title": "CLI"
        }, 
        {
            "location": "/developers/deploy/", 
            "text": "DevOps - Production Deployment\n\n\nWe use various cloud instances for DataHub application. We use AWS S3 and RDS for storing data and metadata, and the application runs on Heroku.\n\n\nYou can create all the instances and deploy app with one simple command, follow the instructions here: \nhttps://gitlab.com/datopian/datahub-deploy\n\n\nOutline - Conceptually\n\n\n\ngraph TD\n\n  user[fa:fa-user User] --> frontend\n  frontend[Frontend] --> db[Database]\n  frontend --> bits[BitStore - S3]\n\n\n\n\nCurrent Structure\n\n\nThis diagram shows the current deployment architecture.\n\n\n\ngraph TD\n\n  user[fa:fa-user User]\n  bits[BitStore]\n  cloudflare[Cloudflare]\n\n  user --> cloudflare\n  cloudflare --> heroku\n  cloudflare --> bits\n  heroku[Heroku - Flask] --> rds[RDS Database]\n  heroku --> bits\n\n\n\n\nAWS - Old Structure\n\n\nWe are no longer using AWS in this way. However, we have kept this for historical purposes and in case we return to AWS\n\n\n\ngraph TD\n\n  user[fa:fa-user User] --> cloudfront[Cloudfront]\n  cloudfront --> apigateway[API Gateway]\n  apigateway --> lambda[AWS Lambda - Flask via Zappa]\n  cloudfront --> s3assets[S3 Assets]\n  lambda --> rds[RDS Database]\n  lambda --> bits[BitStore]\n  cloudfront --> bits", 
            "title": "Deploy"
        }, 
        {
            "location": "/developers/deploy/#devops-production-deployment", 
            "text": "We use various cloud instances for DataHub application. We use AWS S3 and RDS for storing data and metadata, and the application runs on Heroku.  You can create all the instances and deploy app with one simple command, follow the instructions here:  https://gitlab.com/datopian/datahub-deploy", 
            "title": "DevOps - Production Deployment"
        }, 
        {
            "location": "/developers/deploy/#outline-conceptually", 
            "text": "graph TD\n\n  user[fa:fa-user User] --> frontend\n  frontend[Frontend] --> db[Database]\n  frontend --> bits[BitStore - S3]", 
            "title": "Outline - Conceptually"
        }, 
        {
            "location": "/developers/deploy/#current-structure", 
            "text": "This diagram shows the current deployment architecture.  \ngraph TD\n\n  user[fa:fa-user User]\n  bits[BitStore]\n  cloudflare[Cloudflare]\n\n  user --> cloudflare\n  cloudflare --> heroku\n  cloudflare --> bits\n  heroku[Heroku - Flask] --> rds[RDS Database]\n  heroku --> bits", 
            "title": "Current Structure"
        }, 
        {
            "location": "/developers/deploy/#aws-old-structure", 
            "text": "We are no longer using AWS in this way. However, we have kept this for historical purposes and in case we return to AWS  \ngraph TD\n\n  user[fa:fa-user User] --> cloudfront[Cloudfront]\n  cloudfront --> apigateway[API Gateway]\n  apigateway --> lambda[AWS Lambda - Flask via Zappa]\n  cloudfront --> s3assets[S3 Assets]\n  lambda --> rds[RDS Database]\n  lambda --> bits[BitStore]\n  cloudfront --> bits", 
            "title": "AWS - Old Structure"
        }, 
        {
            "location": "/developers/api/", 
            "text": "DataHub API\n\n\nThe API provides a range of endpoints to query and manage the platform.\n\n\nYou can explore the API via the docs below.\n\n\n\n\n\n \n\n\n\n \n\n\n\n\nwindow.onload = function() {\n  // Build a system\n  const ui = SwaggerUIBundle({\n    url: \"https://staging.datapackaged.com/api/swagger.json\",\n    dom_id: '#swagger-ui',\n    validatorUrl : null,\n    presets: [\n      SwaggerUIBundle.presets.apis,\n      SwaggerUIStandalonePreset\n    ],\n    plugins: [\n      SwaggerUIBundle.plugins.DownloadUrl\n    ],\n    layout: \"StandaloneLayout\"\n  })\n\n  window.ui = ui\n}", 
            "title": "API"
        }, 
        {
            "location": "/developers/api/#datahub-api", 
            "text": "The API provides a range of endpoints to query and manage the platform.  You can explore the API via the docs below.         \nwindow.onload = function() {\n  // Build a system\n  const ui = SwaggerUIBundle({\n    url: \"https://staging.datapackaged.com/api/swagger.json\",\n    dom_id: '#swagger-ui',\n    validatorUrl : null,\n    presets: [\n      SwaggerUIBundle.presets.apis,\n      SwaggerUIStandalonePreset\n    ],\n    plugins: [\n      SwaggerUIBundle.plugins.DownloadUrl\n    ],\n    layout: \"StandaloneLayout\"\n  })\n\n  window.ui = ui\n}", 
            "title": "DataHub API"
        }, 
        {
            "location": "/developers/authorization/", 
            "text": "Authorization Set up\n\n\nAuthorization is the process of giving someone permission to do or have something. In multi-user systems, a system administrator defines for the system which users are allowed access to the system and what privileges of use.\n\n\nWe have a standard access control matrix with 3 axes:\n\n\n\n\nActions: CREATE, READ, WRITE, DELETE, PURGE etc. these can vary among different entities\n\n\nEntities (object): User, Publisher, Package, Package Resource, \u2026\n\n\nUsers: a user or type of user\n\n\n\n\nPermission is a tuple of \n(Users, Entities, Actions)\n\n\nIntroducing Roles\n\n\nIt can be tiresome and inefficient to list for every object all the users permitted to perform a given action. For example:\n\n\n\n\nMany users in an organization get same set of privileges because of their position in the organization.\n\n\nWe want to change the permissions associated with a certain level in the organization and to have those permissions changed for all people in that level\n\n\nA user may change level frequently (ex. user may get promoted)\n\n\n\n\nSo we create roles\n\n\n\n\nPer object roles e.g. Package Owner\n\n\nPer system roles e.g. System Administrator\n\n\nA list or algorithm for assigning Users =\n Roles\n\n\n\n\nAccess control algorithm:\n\nis_allowed(user, entity, action)\n\n\nFor this user: what roles do they have related to this entity and the system?\nGiven those roles: what actions do they have: UNIONrole\n\n\nNote: it would get more complex if some roles deny access. E.g. Role: Spammer might mean you are denied action to posting etc. Right now we don\u2019t have that issue.\n\n\nIs the desired action in that set?\n\n\nRoles\n\n\nThe example roles are given below.\n\n\n\n\nPackage\n\n\nOwner  =\n all actions\n\n\nEditor\n\n\nRead\n\n\nCreate\n\n\nDelete\n\n\nUndelete\n\n\nUpdate\n\n\nTag\n\n\n\n\n\n\nViewer  =\n Only read\n\n\n\n\n\n\nPublisher\n\n\nOwner =\n all actions on Publisher\n\n\nEditor\n\n\nViewMemberList\n\n\nAddMember\n\n\nRemoveMember\n\n\nRead\n\n\n\n\n\n\nViewer =\n Only Read\n\n\n\n\n\n\nSystem\n\n\nLoggedIn\n\n\nPackage::Create\n\n\nPublisher::Create\n\n\n\n\n\n\nAll =\n Package::Read on public packages\n\n\nSysadmin =\n all actions\n\n\n\n\n\n\n\n\nThis\n contains the current roles.\n\n\nBusiness roles\n\n\n\n\nPublisher Owner\n\n\nPublisher::Owner\n\n\n\n\n\n\nPublisher Member\n\n\nPublisher::Editor\n\n\n\n\n\n\n(Logged in) User\n\n\nSystem::LoggedIn\n\n\n\n\n\n\nSys Admin\n\n\nSystem::Sysadmin\n\n\n\n\n\n\nVisitor\n\n\nSystem::Anonymous\n\n\n\n\n\n\n\n\n\n\nNOTE: business roles and authorization roles are distinct. Of course, in implementing access control we will use the business logic inherent in business roles. However, business roles are not explicitly present in the access control system.\n\n\n\n\nActions\n\n\n\n\nNote: not an exhaustive list. \nThis\n contains the current Actions.\n\n\n\n\n\n\nPackage:\n\n\nPackage::Read\n\n\nPackage::Create\n\n\nPackage::Delete\n\n\nPackage::Undelete\n\n\nPackage::Purge\n\n\nPackage::Update\n\n\nPackage::Tag\n\n\n\n\n\n\nPublisher:\n\n\nPublisher::Create\n\n\nPublisher::AddMember\n\n\nPublisher::RemoveMember\n\n\nPublisher::Read\n\n\nPublisher::Delete\n\n\nPublisher::Update\n\n\nPublisher::ViewMemberList\n\n\n\n\n\n\n\n\nExamples\n\n\nFirst time visitor or not logged in:\n\n\nThe business role will be \nSystem::Anonymous\n. So the user can only has the action permission of \nPackage::Read\n.\nSo the user can only view the public data packages.\n\n\nLogged in user:\n\n\nThe business role will be \nSystem::LoggedIn\n . So the user will have permission of :\n\n\n\n\nPublisher::Create\n : The user can create new publisher.\n\n\nPackage::Create\n : The user can create new data package.\n\n\nPackage::Read\n : Can read public data packages", 
            "title": "Authorization"
        }, 
        {
            "location": "/developers/authorization/#authorization-set-up", 
            "text": "Authorization is the process of giving someone permission to do or have something. In multi-user systems, a system administrator defines for the system which users are allowed access to the system and what privileges of use.  We have a standard access control matrix with 3 axes:   Actions: CREATE, READ, WRITE, DELETE, PURGE etc. these can vary among different entities  Entities (object): User, Publisher, Package, Package Resource, \u2026  Users: a user or type of user   Permission is a tuple of  (Users, Entities, Actions)", 
            "title": "Authorization Set up"
        }, 
        {
            "location": "/developers/authorization/#introducing-roles", 
            "text": "It can be tiresome and inefficient to list for every object all the users permitted to perform a given action. For example:   Many users in an organization get same set of privileges because of their position in the organization.  We want to change the permissions associated with a certain level in the organization and to have those permissions changed for all people in that level  A user may change level frequently (ex. user may get promoted)   So we create roles   Per object roles e.g. Package Owner  Per system roles e.g. System Administrator  A list or algorithm for assigning Users =  Roles   Access control algorithm: is_allowed(user, entity, action)  For this user: what roles do they have related to this entity and the system?\nGiven those roles: what actions do they have: UNIONrole  Note: it would get more complex if some roles deny access. E.g. Role: Spammer might mean you are denied action to posting etc. Right now we don\u2019t have that issue.  Is the desired action in that set?", 
            "title": "Introducing Roles"
        }, 
        {
            "location": "/developers/authorization/#roles", 
            "text": "The example roles are given below.   Package  Owner  =  all actions  Editor  Read  Create  Delete  Undelete  Update  Tag    Viewer  =  Only read    Publisher  Owner =  all actions on Publisher  Editor  ViewMemberList  AddMember  RemoveMember  Read    Viewer =  Only Read    System  LoggedIn  Package::Create  Publisher::Create    All =  Package::Read on public packages  Sysadmin =  all actions     This  contains the current roles.", 
            "title": "Roles"
        }, 
        {
            "location": "/developers/authorization/#business-roles", 
            "text": "Publisher Owner  Publisher::Owner    Publisher Member  Publisher::Editor    (Logged in) User  System::LoggedIn    Sys Admin  System::Sysadmin    Visitor  System::Anonymous      NOTE: business roles and authorization roles are distinct. Of course, in implementing access control we will use the business logic inherent in business roles. However, business roles are not explicitly present in the access control system.", 
            "title": "Business roles"
        }, 
        {
            "location": "/developers/authorization/#actions", 
            "text": "Note: not an exhaustive list.  This  contains the current Actions.    Package:  Package::Read  Package::Create  Package::Delete  Package::Undelete  Package::Purge  Package::Update  Package::Tag    Publisher:  Publisher::Create  Publisher::AddMember  Publisher::RemoveMember  Publisher::Read  Publisher::Delete  Publisher::Update  Publisher::ViewMemberList", 
            "title": "Actions"
        }, 
        {
            "location": "/developers/authorization/#examples", 
            "text": "", 
            "title": "Examples"
        }, 
        {
            "location": "/developers/authorization/#first-time-visitor-or-not-logged-in", 
            "text": "The business role will be  System::Anonymous . So the user can only has the action permission of  Package::Read .\nSo the user can only view the public data packages.", 
            "title": "First time visitor or not logged in:"
        }, 
        {
            "location": "/developers/authorization/#logged-in-user", 
            "text": "The business role will be  System::LoggedIn  . So the user will have permission of :   Publisher::Create  : The user can create new publisher.  Package::Create  : The user can create new data package.  Package::Read  : Can read public data packages", 
            "title": "Logged in user:"
        }, 
        {
            "location": "/developers/authentication/", 
            "text": "DataHub Authentication\n\n\nThis page describes authentication of DataHub users. The details provided can be used by developers, willing to contribute to the existing \ndpm\n API client or implement custom client for The DataHub API.\n\n\nThe DataHub Frontend allows users to be registered via \ngithub\n using the web browser. After a successful registration, user will be given unique API-KEY to authenticate with DataHub API server.\n\n\nAPI authentication\n\n\nSome DataHub API methods require client to provide identity of a registered user. To prove its identity, client first has to obtain temporal JWT token, providing permanent API-KEY of a registered user. After that client can pass this token in the header of a request to the API.\n\n\nTo obtain a temporal JWT token, client should send POST request to \n/api/auth/token\n. Request should have json-encoded body with 'username' and 'secret' keys, where 'secret' is an API-KEY of the user:\n\n\nresponse = requests.post(\n        url='https://datapackaged.com/api/auth/token',\n        {'username': 'my_username', 'secret': '1dd5f984bc'}))\n\n\n\nIf the username and API-KEY are valid, server will return json response with JWT token: \n{'token': 'a6d8b887'}\n\n\nauth_token = response.json().get('token')\n\n\n\nThis token should be temporarily stored by the client. To access any API method with authentication, client should include this token in the \"Authorization\" header.\n\n\nrequests.post(api_url, headers={'Authorization', 'Bearer %s' % auth_token})", 
            "title": "Authentication"
        }, 
        {
            "location": "/developers/authentication/#datahub-authentication", 
            "text": "This page describes authentication of DataHub users. The details provided can be used by developers, willing to contribute to the existing  dpm  API client or implement custom client for The DataHub API.  The DataHub Frontend allows users to be registered via  github  using the web browser. After a successful registration, user will be given unique API-KEY to authenticate with DataHub API server.", 
            "title": "DataHub Authentication"
        }, 
        {
            "location": "/developers/authentication/#api-authentication", 
            "text": "Some DataHub API methods require client to provide identity of a registered user. To prove its identity, client first has to obtain temporal JWT token, providing permanent API-KEY of a registered user. After that client can pass this token in the header of a request to the API.  To obtain a temporal JWT token, client should send POST request to  /api/auth/token . Request should have json-encoded body with 'username' and 'secret' keys, where 'secret' is an API-KEY of the user:  response = requests.post(\n        url='https://datapackaged.com/api/auth/token',\n        {'username': 'my_username', 'secret': '1dd5f984bc'}))  If the username and API-KEY are valid, server will return json response with JWT token:  {'token': 'a6d8b887'}  auth_token = response.json().get('token')  This token should be temporarily stored by the client. To access any API method with authentication, client should include this token in the \"Authorization\" header.  requests.post(api_url, headers={'Authorization', 'Bearer %s' % auth_token})", 
            "title": "API authentication"
        }, 
        {
            "location": "/developers/publish/", 
            "text": "Publish\n\n\nExplanation of DataHub publishing flow from client and back-end perspectives.\n\n\nClient Perspective\n\n\nPublishing flow takes the following steps and processes to communicate with DataHub API:\n\n\n\nsequenceDiagram\nUpload Agent CLI->>Upload Agent CLI: Check Data Package valid\nUpload Agent CLI-->>Auth(SSO): Get Session Token (Sends base auth)\nAuth(SSO)-->>Upload Agent CLI: session token\nUpload Agent CLI->>BitStore Upload Auth: Get BitStore Upload token [send session token]\nBitStore Upload Auth->>Auth(SSO): Check key / token\nAuth(SSO)->>BitStore Upload Auth: OK / Not OK\nBitStore Upload Auth->>Upload Agent CLI: S3 auth Token\nUpload Agent CLI->>Data Storage (S3 Raw): Send file plus token\nData Storage (S3 Raw)->>Upload Agent CLI: OK / Not OK\nUpload Agent CLI->>MetaData Storage API: Finalize (After all data uploaded)\nMetaData Storage API->>Upload Agent CLI: OK / Not OK\n\n\n\n\n\n\n\n\nUpload API - see \nPOST /api/package/upload\n in \npackage\n section of \nAPI\n\n\nAuthentication API - see \nPOST /api/auth/token\n in \nauth\n section of \nAPI\n. Read more \nabout authentication\n\n\n[Authorization API][authz] - see \nPOST /api/datastore/authorize\n in \npackage\n section of \nAPI\n. Read more \nabout authorization\n\n\n\n\nSee example \ncode snippet in dpm-py\n\n\n\n\nBack-end perspective\n\n\nDataHub Metadata and Data Flow\n\n\n\n\nPink = service we build\n\n\nBlue = external service\n\n\nDark gray = not yet implemented\n\n\n\n\n\ngraph TD\n\nuser[Publisher fa:fa-user]\nupload-api[\"Upload API (S3 API)\"]\nbitstore(Bitstore S3)\nmetaingestor[Meta Ingestor]\ndataingestor[Data Ingestor]\nmetastore(\"Metastore (RDS)\")\nreadapi[Read API]\ndataproxy[\"DataProxy (convert raw data to json on the fly)\"]\ndatastore[\"Datastore (RDS)\"]\ns3readapi[S3 Get API]\nreaduser[Consumer fa:fa-user]\n\nuser --s3 signed upload url--> upload-api\nupload-api --> bitstore\nbitstore --> metaingestor\nmetaingestor --> metastore\nmetastore --> readapi\nbitstore -.-> dataproxy\nbitstore -.-> dataingestor\ndataingestor -.-> datastore\ndatastore -.-> readapi\nbitstore --> s3readapi\ns3readapi --> readuser\ndataproxy -.-> readuser\nreadapi --> readuser\n\n  classDef extservice fill:lightblue,stroke:#333,stroke-width:4px;\n  classDef notimplemented fill:darkgrey,stroke:#bbb,stroke-width:1px;\n  classDef service fill:pink,stroke:#333,stroke-width:4px;\n  class datastore,dataingestor,dataproxy notimplemented;\n  class bitstore,metastore,s3readapi extservice;\n  class readapi service;\n\n\n\n\n\n\nAuthentication\n\n\nAuthorization\n\n\nMetastore\n - page not yet implemented\n\n\nBitStore\n - page not yet implemented", 
            "title": "Publish"
        }, 
        {
            "location": "/developers/publish/#publish", 
            "text": "Explanation of DataHub publishing flow from client and back-end perspectives.", 
            "title": "Publish"
        }, 
        {
            "location": "/developers/publish/#client-perspective", 
            "text": "Publishing flow takes the following steps and processes to communicate with DataHub API:  \nsequenceDiagram\nUpload Agent CLI->>Upload Agent CLI: Check Data Package valid\nUpload Agent CLI-->>Auth(SSO): Get Session Token (Sends base auth)\nAuth(SSO)-->>Upload Agent CLI: session token\nUpload Agent CLI->>BitStore Upload Auth: Get BitStore Upload token [send session token]\nBitStore Upload Auth->>Auth(SSO): Check key / token\nAuth(SSO)->>BitStore Upload Auth: OK / Not OK\nBitStore Upload Auth->>Upload Agent CLI: S3 auth Token\nUpload Agent CLI->>Data Storage (S3 Raw): Send file plus token\nData Storage (S3 Raw)->>Upload Agent CLI: OK / Not OK\nUpload Agent CLI->>MetaData Storage API: Finalize (After all data uploaded)\nMetaData Storage API->>Upload Agent CLI: OK / Not OK    Upload API - see  POST /api/package/upload  in  package  section of  API  Authentication API - see  POST /api/auth/token  in  auth  section of  API . Read more  about authentication  [Authorization API][authz] - see  POST /api/datastore/authorize  in  package  section of  API . Read more  about authorization   See example  code snippet in dpm-py", 
            "title": "Client Perspective"
        }, 
        {
            "location": "/developers/publish/#back-end-perspective", 
            "text": "DataHub Metadata and Data Flow   Pink = service we build  Blue = external service  Dark gray = not yet implemented   \ngraph TD\n\nuser[Publisher fa:fa-user]\nupload-api[\"Upload API (S3 API)\"]\nbitstore(Bitstore S3)\nmetaingestor[Meta Ingestor]\ndataingestor[Data Ingestor]\nmetastore(\"Metastore (RDS)\")\nreadapi[Read API]\ndataproxy[\"DataProxy (convert raw data to json on the fly)\"]\ndatastore[\"Datastore (RDS)\"]\ns3readapi[S3 Get API]\nreaduser[Consumer fa:fa-user]\n\nuser --s3 signed upload url--> upload-api\nupload-api --> bitstore\nbitstore --> metaingestor\nmetaingestor --> metastore\nmetastore --> readapi\nbitstore -.-> dataproxy\nbitstore -.-> dataingestor\ndataingestor -.-> datastore\ndatastore -.-> readapi\nbitstore --> s3readapi\ns3readapi --> readuser\ndataproxy -.-> readuser\nreadapi --> readuser\n\n  classDef extservice fill:lightblue,stroke:#333,stroke-width:4px;\n  classDef notimplemented fill:darkgrey,stroke:#bbb,stroke-width:1px;\n  classDef service fill:pink,stroke:#333,stroke-width:4px;\n  class datastore,dataingestor,dataproxy notimplemented;\n  class bitstore,metastore,s3readapi extservice;\n  class readapi service;   Authentication  Authorization  Metastore  - page not yet implemented  BitStore  - page not yet implemented", 
            "title": "Back-end perspective"
        }, 
        {
            "location": "/developers/platform/", 
            "text": "Domain model\n\n\nData Package\n\n\nEach Data Package (DataSet) may have zero or more resources and one or more versions. Data Package is owned by Publisher.\n\n\nResources\n - think \"tables\" - Each can map to one or more physical files (usually just one). Think of a data table split into multiple CSV files on disk.\n\n\nVersion of a Data Package\n - similar to git commits and tags. People can mean different things by a \"Version\":\n\n\n\n\nTag - Same as label or version - a nice human usable label e.g. \"v0.3\", \"master\", \"2013\"\n\n\nCommit/Hash - Corresponds to the hash of datapackage.json, with that datapackage.json including all hashes of all data files\n\n\n\n\nWe interpret Version as \"Tag\" concept. *Commit/Hash\" is not supported\n\n\nPublisher\n\n\nPublisher\n is an organization which \"owns\" Data Packages. Publisher may have zero or more Data Packages. Publisher May also have one or more user.\n\n\nUser\n\n\nUser is an authenticated entity, that is member of Publisher organization.\n\n\nImportant:\n Users do not have Data Packages, Publishers do. Users are \nmembers\n of Publishers.\n\n\n\ngraph TD\n\npkg[Package]\nresource[Resource]\nfile[File]\nversion[Version]\nuser[User]\npublisher[Publisher]\n\nsubgraph Package\n  pkg --0..*--> resource\n  resource --1..*--> file\n  pkg --> version\nend\n\nsubgraph Profile\n  publisher --1..*--> user\n  publisher --0..*--> pkg\nend\n\n\n\n\nOverall Architecture\n\n\nOur platform architecture is built on several different components:\n\n\n\n\nCLI\n - Command Line Interface\n\n\nFront-end Web Application\n - API, Login \n Sign-Up and Browse \n Search\n\n\nViews and Renderer\n - Graphs, Charts, Tables and other visualization tools\n\n\n\n\n\ngraph TD\n\nsubgraph Web Frontend\n  frontend[Frontend Webapp]\n  browse[Browse \n&\n Search]\n  login[Login \n&\n Signup]\n  view[Views Renderer]\n  frontend --> browse\n  frontend --> login\nend\n\nsubgraph Users and Permissions\n  user[User]\n  permissions[Permissions]\n  authapi[Auth API]\n  authzapi[Authorization API]\n  login --> authapi\n  authapi --> user\n  authzapi --> permissions\nend\n\nsubgraph BitStore\n  bitstore[\"BitStore (S3)\"]\n  bitstoreapi[BitStore API\nput,get]\n  bitstoreapi --> bitstore\n  browse --> bitstoreapi\nend\n\nsubgraph MetaStore\n  metastore[\"MetaStore (RDS)\"]\n  metaapi[MetaStore API\nread,search,import]\n  metaapi --> metastore\n  browse --> metaapi\nend\n\nsubgraph CLI\n  cli[CLI]\nend", 
            "title": "Platform"
        }, 
        {
            "location": "/developers/platform/#domain-model", 
            "text": "", 
            "title": "Domain model"
        }, 
        {
            "location": "/developers/platform/#data-package", 
            "text": "Each Data Package (DataSet) may have zero or more resources and one or more versions. Data Package is owned by Publisher.  Resources  - think \"tables\" - Each can map to one or more physical files (usually just one). Think of a data table split into multiple CSV files on disk.  Version of a Data Package  - similar to git commits and tags. People can mean different things by a \"Version\":   Tag - Same as label or version - a nice human usable label e.g. \"v0.3\", \"master\", \"2013\"  Commit/Hash - Corresponds to the hash of datapackage.json, with that datapackage.json including all hashes of all data files   We interpret Version as \"Tag\" concept. *Commit/Hash\" is not supported", 
            "title": "Data Package"
        }, 
        {
            "location": "/developers/platform/#publisher", 
            "text": "Publisher  is an organization which \"owns\" Data Packages. Publisher may have zero or more Data Packages. Publisher May also have one or more user.", 
            "title": "Publisher"
        }, 
        {
            "location": "/developers/platform/#user", 
            "text": "User is an authenticated entity, that is member of Publisher organization.  Important:  Users do not have Data Packages, Publishers do. Users are  members  of Publishers.  \ngraph TD\n\npkg[Package]\nresource[Resource]\nfile[File]\nversion[Version]\nuser[User]\npublisher[Publisher]\n\nsubgraph Package\n  pkg --0..*--> resource\n  resource --1..*--> file\n  pkg --> version\nend\n\nsubgraph Profile\n  publisher --1..*--> user\n  publisher --0..*--> pkg\nend", 
            "title": "User"
        }, 
        {
            "location": "/developers/platform/#overall-architecture", 
            "text": "Our platform architecture is built on several different components:   CLI  - Command Line Interface  Front-end Web Application  - API, Login   Sign-Up and Browse   Search  Views and Renderer  - Graphs, Charts, Tables and other visualization tools   \ngraph TD\n\nsubgraph Web Frontend\n  frontend[Frontend Webapp]\n  browse[Browse  &  Search]\n  login[Login  &  Signup]\n  view[Views Renderer]\n  frontend --> browse\n  frontend --> login\nend\n\nsubgraph Users and Permissions\n  user[User]\n  permissions[Permissions]\n  authapi[Auth API]\n  authzapi[Authorization API]\n  login --> authapi\n  authapi --> user\n  authzapi --> permissions\nend\n\nsubgraph BitStore\n  bitstore[\"BitStore (S3)\"]\n  bitstoreapi[BitStore API put,get]\n  bitstoreapi --> bitstore\n  browse --> bitstoreapi\nend\n\nsubgraph MetaStore\n  metastore[\"MetaStore (RDS)\"]\n  metaapi[MetaStore API read,search,import]\n  metaapi --> metastore\n  browse --> metaapi\nend\n\nsubgraph CLI\n  cli[CLI]\nend", 
            "title": "Overall Architecture"
        }, 
        {
            "location": "/publishers/", 
            "text": "Publishers\n\n\nThis section of the DataHub documentation is for data publishers. Here you can learn about getting your data ready for loading into DataHub, and how you can interact with your data once it is loaded.\n\n\n\n\nPublishing a Data Package\n\n\nSign up \n get a secret key\n\n\nInstall command line tool\n\n\nConfigure\n\n\nPublish a dataset\n\n\nView it online\n\n\n\n\n\n\n\n\nPublishing a Data Package\n\n\nSign up \n get a secret key\n\n\nYou can sign up using your GitHub account. Once you are signed in, you will be redirected to a dashboard, where you can find your secret key (access token).\n\n\nInstall command line tool\n\n\nNext you need to install \ndpm\n - the data package manager command line tool:\n\n\n$ [sudo] pip install git+https://github.com/frictionlessdata/dpm-py.git\n\n\n\nConfigure\n\n\nYou will need the secret key (access token) to set your configurations:\n\n\n$ dpm configure\n\n\n Username:  \n your user name \n\n\n Your access_token:  \n you secret key \n\n\n Server URL: https://www.datapackaged.com\n\n\n\nNote: server URL may vary depending on application development stage\n\n\nPublish a dataset\n\n\nWe assume you know what a \nData Package\n is.\n\n\nGo to a directory where your data package is located and publish it:\n\n\n$ cd your-data-package-directory/\n$ dpm publish\n\n\n\nView it online\n\n\nOnce your data package is successfully published, you will get an URL to your dataset on the website. Open the URL in your favourite browser and explore it.", 
            "title": "Getting started"
        }, 
        {
            "location": "/publishers/#publishers", 
            "text": "This section of the DataHub documentation is for data publishers. Here you can learn about getting your data ready for loading into DataHub, and how you can interact with your data once it is loaded.   Publishing a Data Package  Sign up   get a secret key  Install command line tool  Configure  Publish a dataset  View it online", 
            "title": "Publishers"
        }, 
        {
            "location": "/publishers/#publishing-a-data-package", 
            "text": "", 
            "title": "Publishing a Data Package"
        }, 
        {
            "location": "/publishers/#sign-up-get-a-secret-key", 
            "text": "You can sign up using your GitHub account. Once you are signed in, you will be redirected to a dashboard, where you can find your secret key (access token).", 
            "title": "Sign up &amp; get a secret key"
        }, 
        {
            "location": "/publishers/#install-command-line-tool", 
            "text": "Next you need to install  dpm  - the data package manager command line tool:  $ [sudo] pip install git+https://github.com/frictionlessdata/dpm-py.git", 
            "title": "Install command line tool"
        }, 
        {
            "location": "/publishers/#configure", 
            "text": "You will need the secret key (access token) to set your configurations:  $ dpm configure  Username:    your user name    Your access_token:    you secret key    Server URL: https://www.datapackaged.com  Note: server URL may vary depending on application development stage", 
            "title": "Configure"
        }, 
        {
            "location": "/publishers/#publish-a-dataset", 
            "text": "We assume you know what a  Data Package  is.  Go to a directory where your data package is located and publish it:  $ cd your-data-package-directory/\n$ dpm publish", 
            "title": "Publish a dataset"
        }, 
        {
            "location": "/publishers/#view-it-online", 
            "text": "Once your data package is successfully published, you will get an URL to your dataset on the website. Open the URL in your favourite browser and explore it.", 
            "title": "View it online"
        }, 
        {
            "location": "/publishers/cli/", 
            "text": "DPM: The Data Package Manager CLI\n\n\n\n\nGetting started\n\n\nInstallation\n\n\nCommands\n\n\nConfiguration\n\n\nUsage\n\n\nPublish\n\n\nTag\n\n\nDelete\n\n\nUndelete\n\n\n\n\n\n\nLinks\n\n\n\n\nGetting started\n\n\nThe dpm is a command-line tool aimed to help publishers to prepare and upload data to the DataHub. With dpm you will be able to:\n\n\n\n\nValidate your data to ensure its quality\n\n\nPublish Data Package\n\n\nTag uploaded Data Package to create historical snapshot\n\n\nRemove uploaded Data Package that is no longer needed\n\n\n\n\nInstallation\n\n\nYou can install unstable version directly from the code repository:\n\n\npip install git+https://github.com/frictionlessdata/dpm-py.git\n\n\n\nCommands\n\n\nYou can see the latest commands and get help by doing:\n\n\ndpm --help\n\n\n\nYou will see output like this:\n\n\nUsage: dpm [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --version      Show the version and exit.\n  --config TEXT  Use custom config file. Default /home/u1/.dpm/config\n  --debug        Show debug messages\n  --help         Show this message and exit.\n\nCommands:\n  configure     Update configuration options.\n  datavalidate  Validate csv file data, given its path.\n  delete        Delete Data Package from the registry server.\n  publish       Publish Data Package to the registry server.\n  purge         Purge Data Package from the registry server.\n  tag           Tag Data Package on the server.\n  undelete      Undelete Data Package from the registry...\n  validate      Validate Data Package in the current dir.\n\n\n\nConfiguration\n\n\nDpm can be configured using \ndpm configure\n command. It will ask you\nto provide username, access_token and server address of DataHub.\n\n\nThe config is stored in \n~/.dpm/config\n, you can edit it with text editor.\nSimple example config file can look like this:\n\n\nusername = myname\naccess_token = mykey\nserver = server URL for publishing Eg: https://www.datapackaged.com\n\n\n\nUsage\n\n\nPublish\n\n\nTo publish a Data Package, go to the Data Package directory (with \ndatapackage.json\n) and\nrun:\n\n\ndpm publish\n\n\n\nIf your configured \nusername\n and \naccess_token\n are correct, dpm will\nupload datapackage.json and all relevant resources to the registry server.\n\n\nTag\n\n\nTo create historical snapshot of your data, you can tag previously uploaded datapackage on the server. Use \ndpm tag\n command:\n\n\ncd datapackage-dir\ndpm tag v1.1\n\nThis will copy the latest version of the Data Package to a separate location in the BitStore. This way you will be able keep a copy of your Data Package at this particular point in time.\n\n\nDelete\n\n\nYou have two choices: delete Data Package completely from the server (\npurge\n) or make the datapackage invisible to everyone except you (\ndelete\n). You can use \ndpm purge\n and \ndpm delete\n accordingly:\n\n\ncd datapackage-dir\ndpm delete\n# or purge it completely\ndpm purge\n\n\n\nUndelete\n\n\nYou can restore your Data Package using \nundelete\n command.\n\n\ndpm undelete\n\nNote that this only works on packages with soft delete (\ndpm delete\n), you can not undelete ones with hard delete (\ndpm purge\n)\n\n\nLinks\n\n\n\n\nCode repo", 
            "title": "CLI"
        }, 
        {
            "location": "/publishers/cli/#dpm-the-data-package-manager-cli", 
            "text": "Getting started  Installation  Commands  Configuration  Usage  Publish  Tag  Delete  Undelete    Links", 
            "title": "DPM: The Data Package Manager CLI"
        }, 
        {
            "location": "/publishers/cli/#getting-started", 
            "text": "The dpm is a command-line tool aimed to help publishers to prepare and upload data to the DataHub. With dpm you will be able to:   Validate your data to ensure its quality  Publish Data Package  Tag uploaded Data Package to create historical snapshot  Remove uploaded Data Package that is no longer needed", 
            "title": "Getting started"
        }, 
        {
            "location": "/publishers/cli/#installation", 
            "text": "You can install unstable version directly from the code repository:  pip install git+https://github.com/frictionlessdata/dpm-py.git", 
            "title": "Installation"
        }, 
        {
            "location": "/publishers/cli/#commands", 
            "text": "You can see the latest commands and get help by doing:  dpm --help  You will see output like this:  Usage: dpm [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --version      Show the version and exit.\n  --config TEXT  Use custom config file. Default /home/u1/.dpm/config\n  --debug        Show debug messages\n  --help         Show this message and exit.\n\nCommands:\n  configure     Update configuration options.\n  datavalidate  Validate csv file data, given its path.\n  delete        Delete Data Package from the registry server.\n  publish       Publish Data Package to the registry server.\n  purge         Purge Data Package from the registry server.\n  tag           Tag Data Package on the server.\n  undelete      Undelete Data Package from the registry...\n  validate      Validate Data Package in the current dir.", 
            "title": "Commands"
        }, 
        {
            "location": "/publishers/cli/#configuration", 
            "text": "Dpm can be configured using  dpm configure  command. It will ask you\nto provide username, access_token and server address of DataHub.  The config is stored in  ~/.dpm/config , you can edit it with text editor.\nSimple example config file can look like this:  username = myname\naccess_token = mykey\nserver = server URL for publishing Eg: https://www.datapackaged.com", 
            "title": "Configuration"
        }, 
        {
            "location": "/publishers/cli/#usage", 
            "text": "", 
            "title": "Usage"
        }, 
        {
            "location": "/publishers/cli/#publish", 
            "text": "To publish a Data Package, go to the Data Package directory (with  datapackage.json ) and\nrun:  dpm publish  If your configured  username  and  access_token  are correct, dpm will\nupload datapackage.json and all relevant resources to the registry server.", 
            "title": "Publish"
        }, 
        {
            "location": "/publishers/cli/#tag", 
            "text": "To create historical snapshot of your data, you can tag previously uploaded datapackage on the server. Use  dpm tag  command:  cd datapackage-dir\ndpm tag v1.1 \nThis will copy the latest version of the Data Package to a separate location in the BitStore. This way you will be able keep a copy of your Data Package at this particular point in time.", 
            "title": "Tag"
        }, 
        {
            "location": "/publishers/cli/#delete", 
            "text": "You have two choices: delete Data Package completely from the server ( purge ) or make the datapackage invisible to everyone except you ( delete ). You can use  dpm purge  and  dpm delete  accordingly:  cd datapackage-dir\ndpm delete\n# or purge it completely\ndpm purge", 
            "title": "Delete"
        }, 
        {
            "location": "/publishers/cli/#undelete", 
            "text": "You can restore your Data Package using  undelete  command.  dpm undelete \nNote that this only works on packages with soft delete ( dpm delete ), you can not undelete ones with hard delete ( dpm purge )", 
            "title": "Undelete"
        }, 
        {
            "location": "/publishers/cli/#links", 
            "text": "Code repo", 
            "title": "Links"
        }
    ]
}